"""
Context extraction API endpoint
Extracts and returns page context without ad matching
"""
from fastapi import APIRouter, HTTPException, Request
from typing import Dict, Any, List
from datetime import datetime
from pathlib import Path

from models.ad import AdRequest
from context.extractor import context_extractor
from context.enricher import context_enricher
from embeddings.matcher import product_matcher
from storage.products import product_storage
from services.prompt_service import create_batch_prompts
from services.ai_image_service import ai_image_service

router = APIRouter()


def convert_image_path_to_url(image_path: str, api_base_url: str = "") -> str:
    """
    Convert local image path to a URL that can be served by the backend.
    
    Args:
        image_path: Local file path (e.g., /Users/.../assets/products/image.jpg)
        api_base_url: Base URL of the API (e.g., http://localhost:9000)
    
    Returns:
        URL path (e.g., /assets/products/image.jpg or full URL if api_base_url provided)
    """
    # If already a URL, return as-is
    if image_path.startswith('http://') or image_path.startswith('https://'):
        return image_path
    
    # Extract filename from path
    path_obj = Path(image_path)
    filename = path_obj.name
    
    # Build URL path
    url_path = f"/assets/products/{filename}"
    
    # If api_base_url provided, return full URL
    if api_base_url:
        return f"{api_base_url.rstrip('/')}{url_path}"
    
    return url_path


@router.post("/extract_context")
async def extract_context(ad_request: AdRequest, request: Request) -> Dict[str, Any]:
    """
    Extract page context using Apify crawler and match products
    
    Flow:
    1. Receive URL and basic info from SDK
    2. Trigger Apify to crawl the URL
    3. Wait for Apify to extract all content
    4. Generate page embedding
    5. Match products using semantic similarity
    6. Return enriched context with matched products
    
    Args:
        ad_request: Minimal context from SDK (URL + environment)
    
    Returns:
        Complete extracted context with matched products
    """
    try:
        # Build minimal SDK context
        sdk_context = context_extractor.extract_sdk_context(ad_request)
        
        # Get ALL data from Apify (waits for crawl)
        merged_context = await context_enricher.get_or_enrich(sdk_context)
        
        # Get all products
        products = product_storage.get_all(active_only=True)
        
        # Match products if page has embedding
        # Embedding is generated by enricher when loading from cache if missing
        matched_products = []
        if merged_context.get("has_enriched"):
            # Get page embedding from enriched context (generated by enricher if needed)
            page_embedding = None
            
            from storage.page_context import page_context_storage
            cached_entry = page_context_storage.get(ad_request.url)
            if cached_entry and cached_entry.enriched_context:
                page_embedding = cached_entry.enriched_context.text_embedding
            
            if page_embedding and products:
                print(f"[API] Matching products for {ad_request.url}...")
                # Get page topics for topic-based filtering
                page_topics = merged_context.get("topics", [])
                matches = product_matcher.find_best_products(
                    page_embedding=page_embedding,
                    products=products,
                    top_k=3,  # Return top 3 products
                    min_score=0.0,  # Lower threshold to include more products
                    page_topics=page_topics  # For topic-based filtering
                )
                
                # Format matched products
                # Get API base URL from request (for image URLs)
                # Extract base URL from request: http://host:port
                scheme = request.url.scheme  # http or https
                host = request.url.hostname  # localhost or domain
                port = request.url.port  # 9000 or None if default (80/443)
                
                # Build base URL - always include port if specified
                if port:
                    api_base_url = f"{scheme}://{host}:{port}"
                else:
                    # No port specified, use scheme default (80 for http, 443 for https)
                    api_base_url = f"{scheme}://{host}"
                
                for match in matches:
                    product = match["product"]
                    # Convert local image path to URL
                    image_url = convert_image_path_to_url(product.image_url, api_base_url)
                    
                    matched_products.append({
                        "id": product.id,
                        "name": product.name,
                        "description": product.description[:200],  # Truncate
                        "price": product.price,
                        "currency": product.currency,
                        "image_url": image_url,  # Use converted URL
                        "landing_url": product.landing_url,
                        "match_score": round(match["score"], 3)
                    })
                
                print(f"[API] Matched {len(matched_products)} products")
                
                # Get persona from external website
                persona = None
                if ad_request.persona_data:
                    # Use persona_data directly (from external website)
                    persona = {
                        "time_of_day": ad_request.persona_data.get("time_of_day"),
                        "location": ad_request.persona_data.get("location"),
                        "weather": ad_request.persona_data.get("weather"),
                        "temperature": ad_request.persona_data.get("temperature"),
                        "os": ad_request.persona_data.get("os"),
                        "device_type": ad_request.persona_data.get("device_type"),
                    }
                    print(f"[API] Using persona data from external website: {persona.get('time_of_day')} {persona.get('location')} {persona.get('weather')} {persona.get('temperature')} {persona.get('os')} {persona.get('device_type')}")
                
                # Edit product images to match page styling
                if matched_products and merged_context.get("has_enriched"):
                    print(f"[API] Editing {len(matched_products)} product images to match page styling...")
                    
                    # Prepare page context for prompt generation
                    page_context_for_prompts = {
                        "topics": merged_context.get("topics", []),
                        "keywords": merged_context.get("keywords", []),
                        "visual_styles": merged_context.get("visual_styles", {}) or {}
                    }
                    
                    # Generate prompts for each product (with persona if available)
                    prompts = create_batch_prompts(page_context_for_prompts, matched_products, persona)
                    
                    # Edit all product images in parallel
                    matched_products = await ai_image_service.edit_images_batch(
                        matched_products,
                        prompts,
                        api_base_url
                    )
                    
                    print(f"[API] Image editing complete for {len(matched_products)} products")
            else:
                print("[API] No page embedding available for matching")
        else:
            print("[API] Page not enriched, skipping product matching")
        
        # Return context with matched products (with edited images if available)
        return {
            "success": True,
            "context": {
                "url": merged_context.get("url", ad_request.url),
                "title": merged_context.get("title"),
                "headings": merged_context.get("headings", []),
                "visible_text": merged_context.get("visible_text"),
                "keywords": merged_context.get("keywords", []),
                "topics": merged_context.get("topics", []),
                "visual_styles": merged_context.get("visual_styles", {}),
                "system_info": merged_context.get("system_info", {}),
                "has_enriched": merged_context.get("has_enriched", False),
                "device_type": ad_request.device_type,
                "viewport": {
                    "width": ad_request.viewport_width,
                    "height": ad_request.viewport_height
                },
                "slot_id": ad_request.slot_id
            },
            "matched_products": matched_products,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        print(f"Error extracting context: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Error extracting context: {str(e)}")
